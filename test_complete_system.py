#!/usr/bin/env python3
"""
SISTEMA DE TESTES UNIFICADO E COMPLETO - TarefaV4
Teste abrangente de todos os componentes do sistema de escalabilidade
ConsolidaÃ§Ã£o de todos os testes em um arquivo Ãºnico
"""

import os
import sys
import time
import datetime
import traceback
import json
from pathlib import Path
import psutil
import pkg_resources
import subprocess  # Corrige erro de referÃªncia
from core.utils import run_subprocess, check_file_exists, get_logger
import importlib.metadata

class SystemTester:
    """Classe principal para testes do sistema completo"""
    
    def __init__(self):
        self.test_results = {}
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.warnings = 0
        self.logger = get_logger("SystemTester")
        
    def run_all_tests(self):
        """Executar todos os testes do sistema"""
        print("ğŸ§ª SISTEMA DE TESTES UNIFICADO E COMPLETO")
        print("=" * 70)
        print("ğŸ“‹ Executando verificaÃ§Ã£o abrangente de todos os componentes...")
        print()
        
        # Lista de todos os testes
        test_suite = [
            ("ğŸ”§ ConfiguraÃ§Ã£o e Imports", self.test_imports_and_config),
            ("ğŸ³ Docker e Containers", self.test_docker_system),
            ("â˜¸ï¸  Kubernetes", self.test_kubernetes_system),
            ("ğŸ—ï¸  Infraestrutura", self.test_infrastructure_manager),
            ("ğŸ§  Gerenciamento de ConcorrÃªncia", self.test_concurrency_manager),
            ("âš¡ Executor de Testes", self.test_executor_system),
            ("ğŸ“Š AnÃ¡lise de Resultados", self.test_result_analyzer),
            ("ğŸ“ˆ GeraÃ§Ã£o de GrÃ¡ficos", self.test_chart_generator),
            ("ğŸ” Monitor de Recursos", self.test_resource_monitor),
            ("ğŸŒ AplicaÃ§Ãµes (Cliente/Servidor)", self.test_applications),
            ("ğŸ“ Estrutura de Arquivos", self.test_file_structure),
            ("ğŸ”Œ ConsistÃªncia de ConfiguraÃ§Ãµes", self.test_configuration_consistency),
            ("ğŸ’¾ PersistÃªncia de Dados", self.test_data_persistence),
            ("ğŸ” SeguranÃ§a e ValidaÃ§Ãµes", self.test_security_validations),
            ("âš¡ Performance e Recursos", self.test_performance_resources),
            ("ğŸ”„ IntegraÃ§Ã£o Entre Componentes", self.test_integration),
            ("ğŸ“ VersÃµes e Compatibilidade", self.test_version_compatibility),
            ("ğŸ”’ Robustez e RecuperaÃ§Ã£o", self.test_robustness_recovery),
            ("ğŸ“‹ Qualidade do CÃ³digo", self.test_code_quality),
            ("ğŸŒ Ambiente e DependÃªncias", self.test_environment_dependencies),
            ("ğŸ“Š MÃ©tricas e Monitoramento", self.test_metrics_monitoring),
            ("ğŸš€ Deploy e Escalabilidade", self.test_deployment_scalability),
            ("ğŸ” VersÃµes e DependÃªncias", self.test_version_and_dependencies),
            ("ğŸ› ï¸ API do Gerenciador de Infraestrutura", self.test_infrastructure_manager_api),
            ("ğŸ³ Imagens Docker Essenciais", self.test_docker_images_exist),
            ("ğŸ‹ Compatibilidade de Imagens Docker e K8s", self.test_docker_k8s_image_compatibility),
            ("ğŸš¦ Performance e Estabilidade (paralelo)", self.test_performance_and_stability),
        ]
        
        # Executar cada teste
        for test_name, test_func in test_suite:
            self._run_test_section(test_name, test_func)
        
        # RelatÃ³rio final
        self._generate_final_report()
        
        return self.failed_tests == 0

    def _run_test_section(self, test_name: str, test_func):
        """Executar uma seÃ§Ã£o de testes"""
        print(f"\n{test_name}")
        print("=" * 70)
        try:
            test_func()
        except Exception as e:
            self._log_test("ERRO CRÃTICO", f"{test_name}: {e}", False)
            print(f"âŒ ERRO CRÃTICO: {e}")
            self.logger.error(f"Erro crÃ­tico em {test_name}: {e}", exc_info=True)
            traceback.print_exc()

    def _log_test(self, test_name: str, description: str, passed: bool, warning: bool = False):
        """Registrar resultado de um teste"""
        self.total_tests += 1
        
        if warning:
            self.warnings += 1
            status = "âš ï¸ "
        elif passed:
            self.passed_tests += 1
            status = "âœ…"
        else:
            self.failed_tests += 1
            status = "âŒ"
        
        self.test_results[test_name] = {
            "description": description,
            "passed": passed,
            "warning": warning
        }
        
        print(f"{status} {test_name}: {description}")
        self.logger.info(f"{status} {test_name}: {description}")

    def test_imports_and_config(self):
        """Testar imports e configuraÃ§Ã£o do sistema"""
        # Teste de imports principais
        critical_modules = [
            'core.config',
            'core.infrastructure_manager',
            'core.test_executor',
            'core.concurrency_manager',
            'core.result_analyzer',
            'core.chart_generator',
            'core.resource_monitor'
        ]
        for module in critical_modules:
            try:
                imported = __import__(module, fromlist=[''])
                self._log_test(f"Import {module.split('.')[-1]}", "MÃ³dulo importado com sucesso", True)
                # Testar funÃ§Ãµes factory especÃ­ficas
                factory_name = f'get_{module.split('.')[-1]}'
                if hasattr(imported, factory_name):
                    factory_func = getattr(imported, factory_name)
                    instance = factory_func()
                    self._log_test(f"Factory {module.split('.')[-1]}", "FunÃ§Ã£o factory funcional", True)
            except ImportError as e:
                self._log_test(f"Import {module.split('.')[-1]}", f"Falha na importaÃ§Ã£o: {e}", False)
            except Exception as e:
                self._log_test(f"Import {module.split('.')[-1]}", f"Erro: {e}", False)
        
        # Teste de configuraÃ§Ã£o
        try:
            from core.config import get_config, print_system_info
            config = get_config()
            
            # Verificar atributos essenciais
            essential_attrs = [
                'LANGUAGES', 'SERVERS', 'CLIENTS', 'MESSAGES',
                'DOCKER_USERNAME', 'K8S_NAMESPACE', 'RESULTS_DIR'
            ]
            
            for attr in essential_attrs:
                if hasattr(config, attr):
                    self._log_test(f"Config.{attr}", f"Atributo presente: {getattr(config, attr)}", True)
                else:
                    self._log_test(f"Config.{attr}", "Atributo ausente", False)
            
            # Verificar configuraÃ§Ãµes conservadoras
            if config.PARALLEL_EXECUTION:
                self._log_test("Config Paralela", "ExecuÃ§Ã£o paralela ainda ativa", False)
            else:
                self._log_test("Config Paralela", "ExecuÃ§Ã£o sequencial configurada", True)
                
            if config.BATCH_SIZE <= 1:
                self._log_test("Config Batch", f"Batch size conservador: {config.BATCH_SIZE}", True)
            else:
                self._log_test("Config Batch", f"Batch size alto: {config.BATCH_SIZE}", False)
                
        except Exception as e:
            self._log_test("ConfiguraÃ§Ã£o", f"Erro na configuraÃ§Ã£o: {e}", False)

    def test_docker_system(self):
        """Testar sistema Docker"""
        
        # Verificar Docker instalado
        try:
            result = run_subprocess(['docker', '--version'])
            if result.returncode == 0:
                self._log_test("Docker InstalaÃ§Ã£o", f"Docker disponÃ­vel: {result.stdout.strip()}", True)
            else:
                self._log_test("Docker InstalaÃ§Ã£o", "Docker nÃ£o encontrado", False)
                return
        except FileNotFoundError:
            self._log_test("Docker InstalaÃ§Ã£o", "Docker nÃ£o instalado", False)
            return
        
        # Verificar Docker daemon
        try:
            result = run_subprocess(['docker', 'ps'])
            if result.returncode == 0:
                self._log_test("Docker Daemon", "Docker daemon ativo", True)
            else:
                self._log_test("Docker Daemon", "Docker daemon inativo", False)
        except Exception as e:
            self._log_test("Docker Daemon", f"Erro: {e}", False)
        
        # Verificar imagens necessÃ¡rias
        expected_images = [
            'guimsk/servidor-c:latest',
            'guimsk/servidor-cpp:latest', 
            'guimsk/cliente:latest'
        ]
        
        try:
            result = run_subprocess(['docker', 'images', '--format', '{{.Repository}}:{{.Tag}}'])
            if result.returncode == 0:
                images = result.stdout.strip().split('\n')
                
                for expected in expected_images:
                    if any(expected in img for img in images):
                        self._log_test(f"Docker Image {expected}", "Imagem encontrada", True)
                    else:
                        self._log_test(f"Docker Image {expected}", "Imagem nÃ£o encontrada", False, warning=True)
            
        except Exception as e:
            self._log_test("Docker Images", f"Erro verificando imagens: {e}", False)
        
        # Testar DockerManager
        try:
            from core.infrastructure_manager import DockerManager
            docker_manager = DockerManager()
            self._log_test("DockerManager", "Classe instanciada com sucesso", True)
            
            # Verificar mÃ©todos essenciais
            essential_methods = ['build_and_push_all', 'build_image', 'push_image']
            for method in essential_methods:
                if hasattr(docker_manager, method):
                    self._log_test(f"DockerManager.{method}", "MÃ©todo disponÃ­vel", True)
                else:
                    self._log_test(f"DockerManager.{method}", "MÃ©todo ausente", False)
                    
        except Exception as e:
            self._log_test("DockerManager", f"Erro: {e}", False)

    def test_kubernetes_system(self):
        """Testar sistema Kubernetes"""
        
        # Verificar kubectl
        try:
            result = subprocess.run(['kubectl', 'version', '--client'], capture_output=True, text=True)
            if result.returncode == 0:
                self._log_test("kubectl", "Cliente kubectl disponÃ­vel", True)
            else:
                self._log_test("kubectl", "kubectl nÃ£o encontrado", False)
                return
        except FileNotFoundError:
            self._log_test("kubectl", "kubectl nÃ£o instalado", False)
            return
        
        # Verificar conectividade com cluster
        try:
            result = subprocess.run(['kubectl', 'cluster-info'], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                self._log_test("K8s Cluster", "Cluster acessÃ­vel", True)
                
                # Verificar nodes
                result = subprocess.run(['kubectl', 'get', 'nodes'], capture_output=True, text=True)
                if result.returncode == 0:
                    nodes = len([line for line in result.stdout.split('\n')[1:] if line.strip()])
                    self._log_test("K8s Nodes", f"{nodes} nodes disponÃ­veis", True)
                
            else:
                self._log_test("K8s Cluster", "Cluster inacessÃ­vel", False, warning=True)
        except subprocess.TimeoutExpired:
            self._log_test("K8s Cluster", "Timeout conectando ao cluster", False, warning=True)
        except Exception as e:
            self._log_test("K8s Cluster", f"Erro: {e}", False, warning=True)
        
        # Verificar namespace do projeto (serÃ¡ criado dinamicamente se necessÃ¡rio)
        try:
            from core.config import get_config
            config = get_config()
            result = subprocess.run(['kubectl', 'get', 'namespace', config.K8S_NAMESPACE], 
                                   capture_output=True, text=True)
            if result.returncode == 0:
                self._log_test("K8s Namespace", f"Namespace {config.K8S_NAMESPACE} existe", True)
            else:
                self._log_test("K8s Namespace", f"Namespace {config.K8S_NAMESPACE} serÃ¡ criado dinamicamente", True)
        except Exception as e:
            self._log_test("K8s Namespace", f"Erro verificando namespace: {e}", False)
        
        # Testar KubernetesManager
        try:
            from core.infrastructure_manager import KubernetesManager
            k8s_manager = KubernetesManager()
            self._log_test("KubernetesManager", "Classe instanciada com sucesso", True)
            
            essential_methods = ['setup_namespace', 'deploy_server', 'cleanup_resources']
            for method in essential_methods:
                if hasattr(k8s_manager, method):
                    self._log_test(f"K8sManager.{method}", "MÃ©todo disponÃ­vel", True)
                else:
                    self._log_test(f"K8sManager.{method}", "MÃ©todo ausente", False)
                    
        except Exception as e:
            self._log_test("KubernetesManager", f"Erro: {e}", False)

    def test_infrastructure_manager(self):
        """Testar gerenciador de infraestrutura"""
        
        try:
            from core.infrastructure_manager import get_infrastructure_manager
            infrastructure = get_infrastructure_manager()
            self._log_test("InfrastructureManager", "InstÃ¢ncia criada com sucesso", True)
            
            # Verificar componentes internos
            if hasattr(infrastructure, 'docker_manager'):
                self._log_test("InfraManager.docker", "DockerManager presente", True)
            else:
                self._log_test("InfraManager.docker", "DockerManager ausente", False)
            
            if hasattr(infrastructure, 'k8s') and infrastructure.k8s:
                self._log_test("InfraManager.k8s", "KubernetesManager presente", True)
            else:
                self._log_test("InfraManager.k8s", "KubernetesManager ausente", False)
            
            # Verificar mÃ©todos principais
            essential_methods = [
                'setup_infrastructure', 'cleanup_all', 'build_and_push_all',
                'deploy_servers', 'wait_for_pods_ready'
            ]
            
            for method in essential_methods:
                if hasattr(infrastructure, method):
                    self._log_test(f"InfraManager.{method}", "MÃ©todo disponÃ­vel", True)
                else:
                    self._log_test(f"InfraManager.{method}", "MÃ©todo ausente", False)
            
        except Exception as e:
            self._log_test("InfrastructureManager", f"Erro: {e}", False)

    def test_concurrency_manager(self):
        """Testar gerenciador de concorrÃªncia"""
        
        try:
            from core.concurrency_manager import get_concurrency_manager
            manager = get_concurrency_manager()
            self._log_test("ConcurrencyManager", "InstÃ¢ncia criada com sucesso", True)
            
            # Testar status inicial
            status = manager.get_resource_status()
            if isinstance(status, dict) and 'cpu_percent' in status:
                self._log_test("ConcurrencyManager.status", "Status de recursos funcional", True)
            else:
                self._log_test("ConcurrencyManager.status", "Status invÃ¡lido", False)
            
            # Testar aquisiÃ§Ã£o de slots
            if manager.acquire_pod_slot():
                manager.release_pod_slot()
                self._log_test("ConcurrencyManager.pods", "Controle de pod slots funcional", True)
            else:
                self._log_test("ConcurrencyManager.pods", "Falha no controle de pods", False)
            
            if manager.acquire_test_slot():
                manager.release_test_slot()
                self._log_test("ConcurrencyManager.tests", "Controle de test slots funcional", True)
            else:
                self._log_test("ConcurrencyManager.tests", "Falha no controle de testes", False)
            
            # Testar adaptaÃ§Ã£o
            manager.report_test_success()
            manager.report_test_failure()
            self._log_test("ConcurrencyManager.adapt", "Sistema de adaptaÃ§Ã£o funcional", True)
            
        except Exception as e:
            self._log_test("ConcurrencyManager", f"Erro: {e}", False)

    def test_executor_system(self):
        """Testar sistema executor de testes"""
        
        try:
            from core.test_executor import get_kubernetes_test_executor, TestScenario
            executor = get_kubernetes_test_executor(clear_previous_data=False)
            self._log_test("TestExecutor", "InstÃ¢ncia criada com sucesso", True)
            
            # Testar criaÃ§Ã£o de cenÃ¡rio
            scenario = TestScenario(
                scenario_id="test_validation",
                language="c",
                num_servers=2,
                num_clients=10,
                messages_per_client=1,
                run_number=1
            )
            self._log_test("TestScenario", "CenÃ¡rio criado com sucesso", True)
            
            # Verificar mÃ©todos essenciais
            essential_methods = ['run_all_tests', 'run_single_scenario', 'get_results'
            ]
            for method in essential_methods:
                if hasattr(executor, method):
                    self._log_test(f"TestExecutor.{method}", "MÃ©todo disponÃ­vel", True)
                else:
                    self._log_test(f"TestExecutor.{method}", "MÃ©todo ausente", False)
            
        except Exception as e:
            self._log_test("TestExecutor", f"Erro: {e}", False)

    def test_result_analyzer(self):
        """Testar analisador de resultados"""
        
        try:
            from core.result_analyzer import get_result_analyzer
            analyzer = get_result_analyzer()
            self._log_test("ResultAnalyzer", "InstÃ¢ncia criada com sucesso", True)
            
            # Verificar mÃ©todos de anÃ¡lise
            analysis_methods = ['analyze_results', 'generate_summary', 'export_results']
            for method in analysis_methods:
                if hasattr(analyzer, method):
                    self._log_test(f"ResultAnalyzer.{method}", "MÃ©todo disponÃ­vel", True)
                else:
                    self._log_test(f"ResultAnalyzer.{method}", "MÃ©todo ausente", False)
            
        except Exception as e:
            self._log_test("ResultAnalyzer", f"Erro: {e}", False)

    def test_chart_generator(self):
        """Testar gerador de grÃ¡ficos (novo unificado)"""
        try:
            from core.config import get_config
            import subprocess
            config = get_config()
            script_path = config.CORE_DIR / "unified_chart_generator.py"
            result = subprocess.run([sys.executable, str(script_path)], capture_output=True, text=True)
            if result.returncode == 0:
                self._log_test("UnifiedChartGenerator", "ExecuÃ§Ã£o do script unificado OK", True)
            else:
                self._log_test("UnifiedChartGenerator", f"Erro na execuÃ§Ã£o: {result.stderr}", False)
        except Exception as e:
            self._log_test("UnifiedChartGenerator", f"Erro: {e}", False)

    def test_resource_monitor(self):
        """Testar monitor de recursos"""
        
        try:
            from core.resource_monitor import get_resource_monitor
            monitor = get_resource_monitor()
            self._log_test("ResourceMonitor", "InstÃ¢ncia criada com sucesso", True)
            
            # Testar coleta de recursos
            try:
                import psutil
                self._log_test("ResourceMonitor.psutil", "Psutil disponÃ­vel", True)
            except ImportError:
                self._log_test("ResourceMonitor.psutil", "Psutil nÃ£o encontrado", False)
            
        except Exception as e:
            self._log_test("ResourceMonitor", f"Erro: {e}", False)

    def test_applications(self):
        """Testar aplicaÃ§Ãµes cliente e servidor"""
        
        # Verificar estrutura de diretÃ³rios
        app_dirs = [
            'applications/cliente',
            'applications/servidor', 
            'applications/servidor-c'
        ]
        
        for app_dir in app_dirs:
            if Path(app_dir).exists():
                self._log_test(f"App Dir {app_dir}", "DiretÃ³rio presente", True)
                
                # Verificar arquivos essenciais
                if app_dir == 'applications/cliente':
                    essential_files = ['app.py', 'Dockerfile']
                else:
                    essential_files = ['Dockerfile']
                    
                for file in essential_files:
                    file_path = Path(app_dir) / file
                    if file_path.exists():
                        self._log_test(f"App File {app_dir}/{file}", "Arquivo presente", True)
                    else:
                        self._log_test(f"App File {app_dir}/{file}", "Arquivo ausente", False)
            else:
                self._log_test(f"App Dir {app_dir}", "DiretÃ³rio ausente", False)

    def test_file_structure(self):
        """Testar estrutura de arquivos do projeto"""
        
        # Arquivos essenciais na pasta core
        essential_files = [
            'config.py', 'infrastructure_manager.py', 'test_executor.py',
            'concurrency_manager.py', 'result_analyzer.py',
            'chart_generator.py', 'resource_monitor.py'
        ]
        for file in essential_files:
            if Path('core')/file and (Path('core')/file).exists():
                self._log_test(f"File core/{file}", "Arquivo presente", True)
            else:
                self._log_test(f"File core/{file}", "Arquivo ausente", False)
        # Arquivos essenciais na raiz
        for file in ['executar.py', 'requirements.txt']:
            if Path(file).exists():
                self._log_test(f"File {file}", "Arquivo presente", True)
            else:
                self._log_test(f"File {file}", "Arquivo ausente", False)
        # DiretÃ³rios essenciais
        essential_dirs = [
            'config', 'applications', 'resultados'
        ]
        for dir_name in essential_dirs:
            if Path(dir_name).exists():
                self._log_test(f"Dir {dir_name}", "DiretÃ³rio presente", True)
            else:
                self._log_test(f"Dir {dir_name}", "DiretÃ³rio ausente", False)

    def test_configuration_consistency(self):
        """Testar consistÃªncia entre configuraÃ§Ãµes"""
        
        # Verificar portas consistentes
        port_configs = {
            'config.py': '8000',
            'applications/servidor/Dockerfile': '8000',
            'applications/servidor-c/Dockerfile': '8000'
        }
        
        for file_path, expected_port in port_configs.items():
            if Path(file_path).exists():
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()
                        if expected_port in content:
                            self._log_test(f"Port {file_path}", f"Porta {expected_port} presente", True)
                        else:
                            self._log_test(f"Port {file_path}", f"Porta {expected_port} ausente", False, warning=True)
                except Exception as e:
                    self._log_test(f"Port {file_path}", f"Erro lendo arquivo: {e}", False)
            else:
                self._log_test(f"Port {file_path}", "Arquivo nÃ£o encontrado", False, warning=True)

    def test_data_persistence(self):
        """Testar persistÃªncia de dados"""
        
        # Verificar diretÃ³rio de resultados
        try:
            from core.config import get_config
            config = get_config()
            
            if config.RESULTS_DIR.exists():
                self._log_test("Data Results Dir", "DiretÃ³rio de resultados existe", True)
            else:
                config.RESULTS_DIR.mkdir(parents=True, exist_ok=True)
                self._log_test("Data Results Dir", "DiretÃ³rio de resultados criado", True)
            
            if config.GRAPHICS_DIR.exists():
                self._log_test("Data Graphics Dir", "DiretÃ³rio de grÃ¡ficos existe", True)
            else:
                config.GRAPHICS_DIR.mkdir(parents=True, exist_ok=True)
                self._log_test("Data Graphics Dir", "DiretÃ³rio de grÃ¡ficos criado", True)
            
        except Exception as e:
            self._log_test("Data Persistence", f"Erro: {e}", False)

    def test_security_validations(self):
        """Testar validaÃ§Ãµes de seguranÃ§a"""
        
        # Verificar se nÃ£o hÃ¡ sudo hardcoded em comandos (excluindo comentÃ¡rios e arquivo de teste)
        python_files = [f for f in Path('.').glob('*.py') if f.name != 'test_complete_system.py']
        
        sudo_found = False
        for py_file in python_files:
            try:
                with open(py_file, 'r') as f:
                    lines = f.readlines()
                    for line_num, line in enumerate(lines, 1):
                        # Ignorar comentÃ¡rios e procurar por sudo em comandos reais
                        if line.strip().startswith('#'):
                            continue
                        if 'subprocess' in line and 'sudo' in line:
                            self._log_test(f"Security {py_file}:{line_num}", "Comando sudo encontrado", False, warning=True)
                            sudo_found = True
            except Exception:
                pass
        
        if not sudo_found:
            self._log_test("Security sudo", "Nenhum sudo hardcoded encontrado", True)

    def test_performance_resources(self):
        """Testar configuraÃ§Ãµes de performance"""
        
        try:
            from core.config import get_config
            config = get_config()
            
            # Verificar configuraÃ§Ãµes conservadoras
            if hasattr(config, 'MAX_CONCURRENT_PODS') and config.MAX_CONCURRENT_PODS <= 12:
                self._log_test("Perf Pods", f"Limite conservador de pods: {config.MAX_CONCURRENT_PODS}", True)
            else:
                self._log_test("Perf Pods", "Limite de pods muito alto", False, warning=True)
            
            if hasattr(config, 'WORKER_THREADS') and config.WORKER_THREADS <= 4:
                self._log_test("Perf Threads", f"Threads conservadoras: {config.WORKER_THREADS}", True)
            else:
                self._log_test("Perf Threads", "Muitas threads configuradas", False, warning=True)
            
        except Exception as e:
            self._log_test("Performance", f"Erro: {e}", False)

    def test_integration(self):
        """Testar integraÃ§Ã£o entre componentes"""
        
        try:
            from core.config import get_config
            from core.infrastructure_manager import get_infrastructure_manager
            from core.test_executor import get_kubernetes_test_executor
            from core.concurrency_manager import get_concurrency_manager
            
            config = get_config()
            infrastructure = get_infrastructure_manager()
            executor = get_kubernetes_test_executor(clear_previous_data=False)
            concurrency = get_concurrency_manager()
            
            self._log_test("Integration Chain", "Cadeia de componentes funcional", True)
            
            # Testar comunicaÃ§Ã£o entre componentes
            if hasattr(executor, 'concurrency_manager'):
                self._log_test("Integration Executor-Concurrency", "Executor usa concorrÃªncia", True)
            else:
                self._log_test("Integration Executor-Concurrency", "IntegraÃ§Ã£o ausente", False, warning=True)
            
        except Exception as e:
            self._log_test("Integration", f"Erro na integraÃ§Ã£o: {e}", False)

    def test_version_compatibility(self):
        """Testa se todos os arquivos principais sÃ£o compatÃ­veis entre si e com as dependÃªncias do sistema."""
        from pathlib import Path
        result = True
        # 1. Python version
        min_version = (3, 8)
        version = sys.version_info
        self._log_test("Python Version", f"{version.major}.{version.minor}.{version.micro}", version >= min_version)
        if version < min_version:
            result = False
        # 2. Docker version
        try:
            docker = subprocess.run(["docker", "--version"], capture_output=True, text=True)
            ok = docker.returncode == 0 and "version" in docker.stdout.lower()
            self._log_test("Docker Version", docker.stdout.strip() if ok else "NÃ£o encontrado", ok)
            if not ok:
                result = False
        except Exception as e:
            self._log_test("Docker Version", f"Erro: {e}", False)
            pass
        # 3. kubectl version
        try:
            kubectl = subprocess.run(["kubectl", "version"], capture_output=True, text=True)
            ok = kubectl.returncode == 0 and (kubectl.stdout.strip() or kubectl.stderr.strip())
            version_info = kubectl.stdout.strip() if kubectl.stdout.strip() else kubectl.stderr.strip()
            self._log_test("kubectl Version", version_info if ok else "NÃ£o encontrado", ok)
            if not ok:
                result = False
        except Exception as e:
            self._log_test("kubectl Version", f"Erro: {e}", False)
            result = False
        # 3.1. Kubernetes Server Version (mais robusto)
        try:
            k8s = subprocess.run(["kubectl", "version"], capture_output=True, text=True)
            if k8s.returncode == 0 and (k8s.stdout.strip() or k8s.stderr.strip()):
                lines = k8s.stdout.splitlines() if k8s.stdout else k8s.stderr.splitlines()
                server_line = next((l for l in lines if "Server Version" in l), None)
                if server_line:
                    self._log_test("Kubernetes Version", server_line, True)
                else:
                    self._log_test("Kubernetes Version", "NÃ£o detectada", True, warning=True)
            else:
                self._log_test("Kubernetes Version", "kubectl nÃ£o disponÃ­vel", False)
        except Exception as e:
            self._log_test("Kubernetes Version", f"Erro: {e}", False)
        # 4. requirements.txt
        req_file = Path("requirements.txt")
        if req_file.exists():
            with req_file.open() as f:
                reqs = [l.strip() for l in f if l.strip() and not l.startswith('#')]
            failed = []
            warnings = []
            for req in reqs:
                pkg = req.split('==')[0] if '==' in req else req.split('>=')[0]
                try:
                    version_installed = importlib.metadata.version(pkg)
                    if '==' in req:
                        version_req = req.split('==')[1]
                        if version_installed != version_req:
                            warnings.append(f"{pkg}=={version_installed} (requerido: {version_req})")
                    elif '>=' in req:
                        version_req = req.split('>=')[1]
                        if version_installed < version_req:
                            warnings.append(f"{pkg}=={version_installed} (requerido >= {version_req})")
                except importlib.metadata.PackageNotFoundError:
                    failed.append(pkg)
            if not failed:
                if warnings:
                    self._log_test("Python Dependencies", f"VersÃµes diferentes: {warnings}", True, warning=True)
                else:
                    self._log_test("Python Dependencies", "Todas as dependÃªncias satisfeitas", True)
            else:
                self._log_test("Python Dependencies", f"DependÃªncias faltando: {failed}", False, warning=True)
                result = False
        else:
            self._log_test("Python Dependencies", "requirements.txt nÃ£o encontrado", False, warning=True)
            result = False
        # 5. Import e integraÃ§Ã£o dos mÃ³dulos principais
        try:
            import core.config
            import core.infrastructure_manager
            import core.test_executor
            import core.result_analyzer
            import core.chart_generator
            import core.resource_monitor
            import core.concurrency_manager
            self._log_test("Core Imports", "Todos os mÃ³dulos principais importados", True)
        except Exception as e:
            self._log_test("Core Imports", f"Erro: {e}", False)
            result = False
        # 6. Checagem de integraÃ§Ã£o entre mÃ³dulos
        try:
            from core.infrastructure_manager import get_infrastructure_manager
            from core.test_executor import get_kubernetes_test_executor
            from core.result_analyzer import get_result_analyzer
            from core.chart_generator import get_chart_generator
            from core.resource_monitor import get_resource_monitor
            infra = get_infrastructure_manager()
            executor = get_kubernetes_test_executor()
            analyzer = get_result_analyzer()
            chart = get_chart_generator()
            monitor = get_resource_monitor()
            # Checa se mÃ©todos essenciais existem
            essentials = [
                hasattr(infra, 'build_and_push_all'),
                hasattr(infra, 'deploy_servers'),
                hasattr(executor, 'run_all_tests'),
                hasattr(analyzer, 'analyze_results'),
                hasattr(chart, 'generate_all_3d_charts'),
                hasattr(monitor, 'start_monitoring')
            ]
            if all(essentials):
                self._log_test("Core API Integration", "MÃ³dulos principais integrados", True)
            else:
                self._log_test("Core API Integration", "Faltam mÃ©todos essenciais na integraÃ§Ã£o", False)
                result = False
        except Exception as e:
            self._log_test("Core API Integration", f"Erro: {e}", False)
            result = False
        return result

    def test_robustness_recovery(self):
        """Testar robustez e capacidade de recuperaÃ§Ã£o"""
        
        # Teste de tratamento de erros nos imports
        try:
            # Simular import com erro controlado
            test_modules = ['config', 'infrastructure_manager', 'test_executor']
            found_try = False
            for module_name in test_modules:
                try:
                    module = __import__(module_name)
                    # Verificar se mÃ³dulo tem tratamento de erro bÃ¡sico
                    if hasattr(module, '__file__'):
                        with open(module.__file__, 'r') as f:
                            content = f.read()
                            if 'except' in content and 'try:' in content:
                                found_try = True
                except ImportError:
                    continue
            if found_try:
                self._log_test("Robustness Error Handling", "MÃ³dulos tÃªm tratamento de erro", True)
            else:
                self._log_test("Robustness Error Handling", "Nenhum bloco try/except encontrado nos mÃ³dulos principais", True, warning=True)
        except Exception as e:
            self._log_test("Robustness Error Handling", f"Erro testando robustez: {e}", False)
        
        # Teste de recuperaÃ§Ã£o de falhas de rede (simulado)
        try:
            from core.infrastructure_manager import get_infrastructure_manager
            infra = get_infrastructure_manager()
            
            # Verificar se hÃ¡ mÃ©todos de cleanup/recovery
            recovery_methods = ['cleanup_all', 'cleanup_resources']
            has_recovery = any(hasattr(infra.k8s, method) for method in recovery_methods)
            
            if has_recovery:
                self._log_test("Robustness Recovery", "MÃ©todos de recuperaÃ§Ã£o presentes", True)
            else:
                self._log_test("Robustness Recovery", "MÃ©todos de recuperaÃ§Ã£o ausentes", False, warning=True)
                
        except Exception as e:
            self._log_test("Robustness Recovery", f"Erro testando recuperaÃ§Ã£o: {e}", False)
        
        # Teste de timeout e limites
        try:
            from core.config import get_config
            config = get_config()
            
            timeout_configs = ['K8S_DEPLOYMENT_TIMEOUT', 'MAX_CONCURRENT_PODS']
            has_timeouts = all(hasattr(config, attr) for attr in timeout_configs)
            
            if has_timeouts:
                self._log_test("Robustness Timeouts", "Timeouts configurados", True)
            else:
                self._log_test("Robustness Timeouts", "Timeouts nÃ£o configurados", False, warning=True)
                
        except Exception as e:
            self._log_test("Robustness Timeouts", f"Erro verificando timeouts: {e}", False)

    def test_code_quality(self):
        """Testar qualidade do cÃ³digo"""
        
        # Verificar docstrings nos mÃ³dulos principais
        try:
            main_modules = ['config', 'infrastructure_manager', 'test_executor', 'concurrency_manager']
            documented_modules = 0
            
            for module_name in main_modules:
                try:
                    module = __import__(module_name)
                    if module.__doc__ and module.__doc__.strip():
                        documented_modules += 1
                except:
                    pass
            
            doc_rate = (documented_modules / len(main_modules)) * 100
            if doc_rate >= 80:
                self._log_test("Quality Documentation", f"DocumentaÃ§Ã£o OK ({doc_rate:.0f}%)", True)
            else:
                self._log_test("Quality Documentation", f"DocumentaÃ§Ã£o limitada ({doc_rate:.0f}%)", False, warning=True)
                
        except Exception as e:
            self._log_test("Quality Documentation", f"Erro verificando documentaÃ§Ã£o: {e}", False)
        
        # Verificar complexidade de arquivos (tamanho)
        try:
            python_files = list(Path('.').glob('*.py'))
            large_files = []
            
            for py_file in python_files:
                try:
                    with open(py_file, 'r') as f:
                        lines = len(f.readlines())
                        if lines > 1000:  # Arquivos muito grandes
                            large_files.append(f"{py_file}({lines})")
                except:
                    pass
            
            if len(large_files) <= 2:  # MÃ¡ximo 2 arquivos grandes aceitÃ¡vel
                self._log_test("Quality File Size", "Tamanhos de arquivo OK", True)
            else:
                self._log_test("Quality File Size", f"Arquivos grandes: {len(large_files)}", False, warning=True)
                
        except Exception as e:
            self._log_test("Quality File Size", f"Erro verificando tamanhos: {e}", False)
        
        # Verificar imports redundantes/circulares
        try:
            python_files = [f for f in Path('.').glob('*.py') if f.name != 'test_complete_system.py']
            circular_risk = False
            
            for py_file in python_files:
                try:
                    with open(py_file, 'r') as f:
                        content = f.read()
                        # Verificar padrÃµes que podem indicar imports circulares
                        if content.count('import') > 20:  # Muitos imports podem indicar problema
                            circular_risk = True
                            break
                except:
                    pass
            
            if not circular_risk:
                self._log_test("Quality Imports", "Estrutura de imports OK", True)
            else:
                self._log_test("Quality Imports", "PossÃ­vel complexidade de imports", False, warning=True)
                
        except Exception as e:
            self._log_test("Quality Imports", f"Erro verificando imports: {e}", False)

    def test_environment_dependencies(self):
        """Testar ambiente e dependÃªncias do sistema"""
        
        # Verificar variÃ¡veis de ambiente necessÃ¡rias
        try:
            env_vars = ['PATH', 'HOME']
            optional_vars = ['DOCKER_USERNAME', 'KUBECONFIG']
            
            required_ok = all(os.getenv(var) for var in env_vars)
            optional_count = sum(1 for var in optional_vars if os.getenv(var))
            
            if required_ok:
                self._log_test("Environment Required", "VariÃ¡veis requeridas OK", True)
            else:
                self._log_test("Environment Required", "VariÃ¡veis requeridas ausentes", False)
            
            self._log_test("Environment Optional", f"VariÃ¡veis opcionais: {optional_count}/{len(optional_vars)}", True)
            
        except Exception as e:
            self._log_test("Environment Variables", f"Erro verificando ambiente: {e}", False)
        
        # Verificar ferramentas do sistema
        try:
            system_tools = ['docker', 'kubectl', 'python3', 'pip']
            available_tools = []
            
            for tool in system_tools:
                try:
                    result = subprocess.run(['which', tool], capture_output=True, text=True)
                    if result.returncode == 0:
                        available_tools.append(tool)
                except:
                    pass
            
            tool_rate = (len(available_tools) / len(system_tools)) * 100
            if tool_rate >= 75:
                self._log_test("Environment Tools", f"Ferramentas OK ({tool_rate:.0f}%)", True)
            else:
                self._log_test("Environment Tools", f"Ferramentas limitadas ({tool_rate:.0f}%)", False, warning=True)
                
        except Exception as e:
            self._log_test("Environment Tools", f"Erro verificando ferramentas: {e}", False)
        
        # Verificar permissÃµes de escrita
        try:
            test_dirs = ['resultados', '.']
            write_ok = True
            
            for test_dir in test_dirs:
                test_file = Path(test_dir) / f'.test_write_{int(time.time())}'
                try:
                    test_file.write_text('test')
                    test_file.unlink()
                except:
                    write_ok = False
                    break
            
            if write_ok:
                self._log_test("Environment Permissions", "PermissÃµes de escrita OK", True)
            else:
                self._log_test("Environment Permissions", "Problemas de permissÃ£o", False)
                
        except Exception as e:
            self._log_test("Environment Permissions", f"Erro verificando permissÃµes: {e}", False)

    def test_metrics_monitoring(self):
        """Testar sistema de mÃ©tricas e monitoramento"""
        
        # Verificar se psutil estÃ¡ funcionando
        try:
            import psutil
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            
            if cpu_percent >= 0 and memory.total > 0:
                self._log_test("Metrics System", f"CPU: {cpu_percent:.1f}%, RAM: {memory.percent:.1f}%", True)
            else:
                self._log_test("Metrics System", "Dados de sistema invÃ¡lidos", False)
                
        except Exception as e:
            self._log_test("Metrics System", f"Erro coletando mÃ©tricas: {e}", False)
        
        # Verificar geraÃ§Ã£o de logs estruturados
        try:
            from core.resource_monitor import get_resource_monitor
            monitor = get_resource_monitor()
            
            # Verificar se tem mÃ©todos de coleta
            metrics_methods = ['get_system_metrics', 'collect_metrics']
            has_metrics = any(hasattr(monitor, method) for method in metrics_methods)
            
            if has_metrics:
                self._log_test("Metrics Collection", "Coleta de mÃ©tricas disponÃ­vel", True)
            else:
                self._log_test("Metrics Collection", "MÃ©todos de mÃ©tricas limitados", False, warning=True)
                
        except Exception as e:
            self._log_test("Metrics Collection", f"Erro verificando coleta: {e}", False)
        
        # Verificar capacidade de monitoramento contÃ­nuo
        try:
            from core.resource_monitor import get_resource_monitor
            monitor = get_resource_monitor()
            # Teste de monitoramento contÃ­nuo
            try:
                t = monitor.start_continuous_monitoring(interval=0.1, duration=1)
                t.join()
                snapshots = monitor.stop_continuous_monitoring()
                if isinstance(snapshots, list) and len(snapshots) > 0 and 'cpu_percent' in snapshots[0]:
                    self._log_test("Metrics Monitoring", "Monitoramento contÃ­nuo OK", True)
                else:
                    self._log_test("Metrics Monitoring", "Monitoramento contÃ­nuo limitado", False, warning=True)
            except Exception as e:
                self._log_test("Metrics Monitoring", f"Erro no monitoramento contÃ­nuo: {e}", False, warning=True)
        except Exception as e:
            self._log_test("Metrics Monitoring", f"Erro verificando monitoramento: {e}", False)

    def test_deployment_scalability(self):
        """Testar capacidades de deploy e escalabilidade"""
        
        # Verificar configuraÃ§Ãµes de escalabilidade
        try:
            from core.config import get_config
            config = get_config()
            
            scale_configs = ['MAX_CONCURRENT_PODS', 'WORKER_THREADS', 'SERVERS', 'CLIENTS']
            has_scale_config = all(hasattr(config, attr) for attr in scale_configs)
            
            if has_scale_config:
                max_pods = getattr(config, 'MAX_CONCURRENT_PODS', 0)
                max_servers = max(getattr(config, 'SERVERS', [0]))
                max_clients = max(getattr(config, 'CLIENTS', [0]))
                
                self._log_test("Scale Configuration", f"Pods: {max_pods}, Servers: {max_servers}, Clients: {max_clients}", True)
            else:
                self._log_test("Scale Configuration", "ConfiguraÃ§Ãµes de escala ausentes", False, warning=True)
                
        except Exception as e:
            self._log_test("Scale Configuration", f"Erro verificando escalabilidade: {e}", False)
        
        # Verificar suporte a deploy paralelo
        try:
            from core.infrastructure_manager import get_infrastructure_manager
            infra = get_infrastructure_manager()
            
            # Verificar se DockerManager suporta paralelo
            has_parallel_build = hasattr(infra.docker, 'build_and_push_all')
            has_parallel_deploy = hasattr(infra.k8s, 'deploy_servers')
            
            if has_parallel_build and has_parallel_deploy:
                self._log_test("Scale Parallel", "Deploy paralelo suportado", True)
            else:
                self._log_test("Scale Parallel", "Deploy paralelo limitado", False, warning=True)
                
        except Exception as e:
            self._log_test("Scale Parallel", f"Erro verificando deploy paralelo: {e}", False)
        
        # Verificar limites de recursos
        try:
            from core.config import get_config
            config = get_config()
            
            if hasattr(config, 'RESOURCE_LIMITS') and hasattr(config, 'RESOURCE_REQUESTS'):
                limits = config.RESOURCE_LIMITS
                requests = config.RESOURCE_REQUESTS
                
                if isinstance(limits, dict) and isinstance(requests, dict):
                    self._log_test("Scale Resources", "Limites de recursos configurados", True)
                else:
                    self._log_test("Scale Resources", "Limites nÃ£o sÃ£o dicionÃ¡rios", False, warning=True)
            else:
                self._log_test("Scale Resources", "Limites de recursos ausentes", False, warning=True)
                
        except Exception as e:
            self._log_test("Scale Resources", f"Erro verificando limites: {e}", False)

    def test_version_and_dependencies(self):
        """Testa versÃ£o do Python, Docker, kubectl e dependÃªncias do requirements.txt"""
        from pathlib import Path
        # Python
        version = sys.version_info
        self._log_test("Python Version", f"{version.major}.{version.minor}.{version.micro}", version >= (3,8))
        # Docker
        try:
            result = subprocess.run(["docker", "--version"], capture_output=True, text=True)
            ok = result.returncode == 0 and "version" in result.stdout.lower()
            self._log_test("Docker Version", result.stdout.strip() if ok else "NÃ£o encontrado", ok)
        except Exception as e:
            self._log_test("Docker Version", f"Erro: {e}", False)
            pass
        # kubectl (ajustado: aceita qualquer saÃ­da vÃ¡lida, como nos outros testes)
        try:
            result = subprocess.run(["kubectl", "version"], capture_output=True, text=True)
            ok = result.returncode == 0 and (result.stdout.strip() or result.stderr.strip())
            version_info = result.stdout.strip() if result.stdout.strip() else result.stderr.strip()
            self._log_test("kubectl Version", version_info if ok else "NÃ£o encontrado", ok)
        except Exception as e:
            self._log_test("kubectl Version", f"Erro: {e}", False)
            pass
        # requirements.txt
        req_file = Path("requirements.txt")
        if req_file.exists():
            with req_file.open() as f:
                reqs = [l.strip() for l in f if l.strip() and not l.startswith('#')]
            failed = []
            warnings = []
            for req in reqs:
                pkg = req.split('==')[0] if '==' in req else req.split('>=')[0]
                try:
                    version_installed = importlib.metadata.version(pkg)
                    if '==' in req:
                        version_req = req.split('==')[1]
                        if version_installed != version_req:
                            warnings.append(f"{pkg}=={version_installed} (requerido: {version_req})")
                    elif '>=' in req:
                        version_req = req.split('>=')[1]
                        if version_installed < version_req:
                            warnings.append(f"{pkg}=={version_installed} (requerido >= {version_req})")
                except importlib.metadata.PackageNotFoundError:
                    failed.append(pkg)
            if not failed:
                if warnings:
                    self._log_test("Python Dependencies", f"VersÃµes diferentes: {warnings}", True, warning=True)
                else:
                    self._log_test("Python Dependencies", "Todas as dependÃªncias satisfeitas", True)
            else:
                self._log_test("Python Dependencies", f"DependÃªncias faltando: {failed}", False, warning=True)
                result = False
        else:
            self._log_test("Python Dependencies", "requirements.txt nÃ£o encontrado", False, warning=True)
            result = False

    def test_infrastructure_manager_api(self):
        """Testa se InfrastructureManager expÃµe mÃ©todos e aliases essenciais"""
        try:
            from core.infrastructure_manager import get_infrastructure_manager
            infra = get_infrastructure_manager()
            attrs = ["docker", "k8s", "build_and_push_all", "deploy_servers", "run_clients", "setup_infrastructure", "wait_for_pods_ready", "cleanup_all"]
            missing = [a for a in attrs if not hasattr(infra, a)]
            if not missing:
                self._log_test("InfraManager API", "Todos os mÃ©todos/aliases presentes", True)
            else:
                self._log_test("InfraManager API", f"Faltando: {missing}", False)
        except Exception as e:
            self._log_test("InfraManager API", f"Erro: {e}", False)

    def test_docker_images_exist(self):
        """Testa se as imagens Docker essenciais existem localmente"""
        try:
            from core.config import get_config
            config = get_config()
            images = [
                config.get_docker_image_name("cliente"),
                config.get_docker_image_name("servidor", "c"),
                config.get_docker_image_name("servidor", "cpp")
            ]
            missing = []
            import subprocess
            for img in images:
                result = subprocess.run(["docker", "images", img, "--quiet"], capture_output=True, text=True)
                if not (result.returncode == 0 and result.stdout.strip()):
                    missing.append(img)
            if not missing:
                self._log_test("Docker Images", "Todas as imagens essenciais existem", True)
            else:
                self._log_test("Docker Images", f"Imagens faltando: {missing}", False, warning=True)
        except Exception as e:
            self._log_test("Docker Images", f"Erro: {e}", False)

    def test_docker_k8s_image_compatibility(self):
        """Testa se as imagens Docker essenciais sÃ£o compatÃ­veis entre si e com a versÃ£o do Kubernetes instalada."""
        import subprocess
        from core.config import get_config
        config = get_config()
        images = [
            config.get_docker_image_name("cliente"),
            config.get_docker_image_name("servidor", "c"),
            config.get_docker_image_name("servidor", "cpp")
        ]
        # 1. Verificar se todas as imagens existem localmente
        missing = []
        for img in images:
            result = subprocess.run(["docker", "images", img, "--quiet"], capture_output=True, text=True)
            if not (result.returncode == 0 and result.stdout.strip()):
                missing.append(img)
        if not missing:
            self._log_test("Docker Images Exist", "Todas as imagens essenciais existem", True)
        else:
            self._log_test("Docker Images Exist", f"Imagens faltando: {missing}", False, warning=True)
        # 2. Verificar arquitetura das imagens (devem ser compatÃ­veis entre si e com o cluster)
        archs = set()
        for img in images:
            try:
                inspect = subprocess.run(["docker", "image", "inspect", img, "--format", "{{.Architecture}}"], capture_output=True, text=True)
                if inspect.returncode == 0:
                    arch = inspect.stdout.strip()
                    if arch:
                        archs.add(arch)
            except Exception:
                pass
        if len(archs) == 1:
            self._log_test("Docker Image Architecture", f"Arquitetura Ãºnica: {list(archs)[0]}", True)
        elif len(archs) == 0:
            self._log_test("Docker Image Architecture", "Arquitetura nÃ£o detectada (todas vazias)", True, warning=True)
        else:
            self._log_test("Docker Image Architecture", f"Arquiteturas diferentes: {archs}", False, warning=True)
        # 3. Verificar versÃ£o do Kubernetes
        try:
            k8s = subprocess.run(["kubectl", "version"], capture_output=True, text=True)
            if k8s.returncode == 0 and (k8s.stdout.strip() or k8s.stderr.strip()):
                lines = k8s.stdout.splitlines() if k8s.stdout else k8s.stderr.splitlines()
                server_line = next((l for l in lines if "Server Version" in l), None)
                if server_line:
                    self._log_test("Kubernetes Version", server_line, True)
                else:
                    self._log_test("Kubernetes Version", "NÃ£o detectada", True, warning=True)
            else:
                self._log_test("Kubernetes Version", "kubectl nÃ£o disponÃ­vel", False)
        except Exception as e:
            self._log_test("Kubernetes Version", f"Erro: {e}", False)
        # 4. Verificar se as imagens suportam a versÃ£o do Kubernetes (checa se sÃ£o recentes, multi-arch, etc)
        # Para simplificaÃ§Ã£o, checa se as imagens foram criadas nos Ãºltimos 2 anos
        now = datetime.datetime.now(datetime.timezone.utc)
        outdated = []
        for img in images:
            try:
                inspect = subprocess.run(["docker", "image", "inspect", img, "--format", "{{.Created}}"], capture_output=True, text=True)
                if inspect.returncode == 0:
                    created_str = inspect.stdout.strip()
                    try:
                        created_time = datetime.datetime.strptime(created_str[:19], "%Y-%m-%dT%H:%M:%S").replace(tzinfo=datetime.timezone.utc)
                        age_days = (now - created_time).days
                        if age_days > 730:
                            outdated.append((img, age_days))
                    except Exception:
                        pass
            except Exception:
                pass
        if not outdated:
            self._log_test("Docker Image Age", "Todas as imagens sÃ£o recentes (<2 anos)", True)
        else:
            self._log_test("Docker Image Age", f"Imagens antigas: {outdated}", False, warning=True)

    def test_performance_and_stability(self):
        """Teste de performance e estabilidade com configuraÃ§Ã£o mÃ¡xima segura"""
        try:
            from core.config import get_config
            from core.test_executor import get_kubernetes_test_executor
            config = get_config()
            executor = get_kubernetes_test_executor(clear_previous_data=True)
            start = time.time()
            # Executa apenas um subconjunto para validaÃ§Ã£o rÃ¡pida
            old_servers = config.SERVERS
            old_clients = config.CLIENTS
            old_messages = config.MESSAGES
            config.SERVERS = [max(old_servers)]
            config.CLIENTS = [max(old_clients)]
            config.MESSAGES = [max(old_messages)]
            config.RUNS_PER_CONFIG = 2
            success = executor.run_all_tests()
            elapsed = time.time() - start
            # Restaura config
            config.SERVERS = old_servers
            config.CLIENTS = old_clients
            config.MESSAGES = old_messages
            config.RUNS_PER_CONFIG = 10
            if success:
                self._log_test("Performance e Estabilidade (paralelo)", f"ExecuÃ§Ã£o mÃ¡xima segura OK em {elapsed:.1f}s", True)
            else:
                self._log_test("Performance e Estabilidade (paralelo)", "Falha na execuÃ§Ã£o mÃ¡xima segura", False)
        except Exception as e:
            self._log_test("Performance e Estabilidade (paralelo)", f"Erro: {e}", False)

    def _generate_final_report(self):
        """Gerar relatÃ³rio final dos testes"""
        print("\n" + "=" * 70)
        print("ğŸ“‹ RELATÃ“RIO FINAL DOS TESTES")
        print("=" * 70)
        
        # EstatÃ­sticas gerais
        success_rate = (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0
        
        print(f"ğŸ“Š ESTATÃSTICAS GERAIS:")
        print(f"   â€¢ Total de testes: {self.total_tests}")
        print(f"   â€¢ âœ… Sucessos: {self.passed_tests}")
        print(f"   â€¢ âŒ Falhas: {self.failed_tests}")
        print(f"   â€¢ âš ï¸  Avisos: {self.warnings}")
        print(f"   â€¢ ğŸ“ˆ Taxa de sucesso: {success_rate:.1f}%")
        
        # Status geral
        if self.failed_tests == 0:
            print(f"\nğŸ‰ RESULTADO: âœ… TODOS OS TESTES PASSARAM!")
            print(f"ğŸš€ Sistema pronto para execuÃ§Ã£o completa")
        elif self.failed_tests <= 3:
            print(f"\nâš ï¸  RESULTADO: ğŸŸ¡ ALGUNS PROBLEMAS ENCONTRADOS")
            print(f"ğŸ”§ Sistema funcional mas necessita ajustes")
        else:
            print(f"\nâŒ RESULTADO: ğŸ”´ MUITOS PROBLEMAS ENCONTRADOS")
            print(f"ğŸ› ï¸  Sistema necessita correÃ§Ãµes significativas")
        
        # RecomendaÃ§Ãµes
        print(f"\nğŸ’¡ RECOMENDAÃ‡Ã•ES:")
        if self.failed_tests == 0:
            print(f"   â€¢ Sistema validado e pronto para uso")
            print(f"   â€¢ Execute: python3 executar.py")
        else:
            print(f"   â€¢ Corrija os {self.failed_tests} testes falhando")
            print(f"   â€¢ Revise os {self.warnings} avisos")
            print(f"   â€¢ Execute novamente os testes apÃ³s correÃ§Ãµes")
        
        # Salvar relatÃ³rio em arquivo
        self._save_test_report()

    def _save_test_report(self):
        """Salvar relatÃ³rio de testes em arquivo"""
        try:
            report_file = Path("test_report.json")
            report = {
                "total_tests": self.total_tests,
                "passed_tests": self.passed_tests,
                "failed_tests": self.failed_tests,
                "warnings": self.warnings,
                "results": self.test_results,
                "timestamp": datetime.datetime.now().isoformat()
            }
            with report_file.open("w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            self.logger.info(f"RelatÃ³rio de testes salvo em {report_file.resolve()}")
        except Exception as e:
            self.logger.error(f"Erro ao salvar relatÃ³rio de testes: {e}")

def main():
    """FunÃ§Ã£o principal"""
    print("ğŸš€ Iniciando Sistema de Testes Unificado...")
    
    tester = SystemTester()
    success = tester.run_all_tests()
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
